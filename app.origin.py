# app.py
import string
import numpy as np
import gradio as gr
import torch
import librosa
from espnet_model_zoo.downloader import ModelDownloader
from espnet2.bin.asr_inference import Speech2Text

TARGET_SR = 16000
TAG = "Shinji Watanabe/librispeech_asr_train_asr_transformer_e18_raw_bpe_sp_valid.acc.best"

def text_normalizer(text: str) -> str:
    text = text.upper()
    return text.translate(str.maketrans("", "", string.punctuation))

print(">>> Loading ASR model (first run may take a while)...")
d = ModelDownloader()
device = "cuda" if torch.cuda.is_available() else "cpu"
speech2text = Speech2Text(
    **d.download_and_unpack(TAG),
    device=device,
    ctc_weight=0.5,
    beam_size=5,
    batch_size=0,
    nbest=1,
    minlenratio=0.0,
    maxlenratio=0.0,
)
print(f">>> Model ready on: {device}")

def transcribe_chunk(file_path: str | None, running_text: str):
    if running_text is None:
        running_text = ""
    if not file_path:
        return running_text, running_text

    try:
        # Gradioê°€ wavë¡œ ë„˜ê²¨ì£¼ë¯€ë¡œ ê·¸ëŒ€ë¡œ ì½ìœ¼ë©´ ë¨
        y, sr = librosa.load(file_path, sr=None, mono=True)
        if sr != TARGET_SR:
            y = librosa.resample(y, orig_sr=sr, target_sr=TARGET_SR)
        y = y.astype(np.float32, copy=False)
    except Exception as e:
        print("[WARN] load failed:", e)
        return running_text, running_text

    try:
        nbests = speech2text(y)
        hyp, *_ = nbests[0]
        piece = text_normalizer(hyp)
    except Exception as e:
        print("[WARN] ASR failed:", e)
        piece = ""

    if piece.strip():
        running_text = (running_text + " " if running_text else "") + piece

    return running_text, running_text

def clear_state():
    return "", ""

with gr.Blocks(title="Real-time ASR (ESPnet + Gradio)") as demo:
    gr.Markdown("## ğŸ¤ Real-time-ish ASR Demo\në§ˆì´í¬ë¥¼ ì¼œë©´ ì¡°ê° ë‹¨ìœ„ë¡œ ì¸ì‹ ê²°ê³¼ê°€ ì•„ë˜ì— ëˆ„ì ë©ë‹ˆë‹¤.")

    state = gr.State("")
    mic = gr.Audio(
        sources=["microphone"],
        streaming=True,
        type="filepath",   # íŒŒì¼ ê²½ë¡œë¡œ ë°›ìŒ
        format="wav",      # Gradioê°€ ë‚´ë¶€ì ìœ¼ë¡œ wavë¡œ ë³€í™˜
        label="Microphone (streaming)",
    )
    out = gr.Textbox(label="Transcript (running)", lines=8, interactive=False)

    mic.stream(fn=transcribe_chunk, inputs=[mic, state], outputs=[state, out])
    gr.Button("Clear").click(fn=clear_state, inputs=None, outputs=[state, out])

if __name__ == "__main__":
    demo.queue().launch()  # ê³µìœ  ì›í•˜ë©´ launch(share=True)
# FirstASR